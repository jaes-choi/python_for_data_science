## 곰세마리
> 곰세마리가 한집에 있어 <br> 
> 아빠곰 엄마곰 애기곰  <br>
> 아빠곰은 뚱뚱해  <br>
> 엄마곰은 날씬해  <br>
> 애기곰은 너무 귀여워  <br>
> 히쭉히쭉 잘한다 <br>

## backpack_list
```python
backpack_list = ['paper', 'orange', 'book', 'paper', 'paper', 'apple', 'paper',
       'paper', 'orange', 'tumbler', 'tumbler', 'paper', 'book', 'pencil',
       'paper', 'tumbler']
```
## plot에서 한글 문제있을 때
```python
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False
```

### agg
```python
# agg를 이용해서 한번에 적용
ta_agg = ta.groupby('발생지시도').agg({'사망자수':['sum','max'],'중상자수':'sum',
                                  '대형사고':['sum','mean','count']})
ta_agg.columns

ta_agg.columns = ['사망','사망_max','중상','대형','대형사고율','사고건수']
ta_agg

# dataframe으로 만들기
pd.DataFrame({'사망': ta.groupby('발생지시도')['사망자수'].sum(), 
              '사망': ta.groupby('발생지시도')['사망자수'].max(), 
              '중상': ta.groupby('발생지시도')['중상자수'].sum(), 
              '대형': ta.groupby('발생지시도')['대형사고'].sum(), 
              '대형사고율': ta.groupby('발생지시도')['대형사고'].mean(),
              '사고건수': ta.groupby('발생지시도')['대형사고'].count()})
```

## matplotlib 실습용 데이터 만들기
```python

# 데이터 만들기 
a = np.arange(1,6)
b = a ** 2
c = (5-a) ** 2
d = a + b + c

np.random.seed(19961213)
N = 200
x = np.random.randn(N)
y1 = 10*x + 5*np.random.randn(N)
y2 = -5*x + 3*np.random.randn(N)+10

# 데이터 만들기
y = pd.DataFrame([y1, y2]).T

# Legend와 Stacked, color
colors=['red','blue']
plt.hist(y, color=colors, label=colors, stacked=True)
plt.legend()
plt.show()
```

### subplots
```python
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8,6))
axes[0,0].hist(y)
axes[0,1].hist(y, 20, color=colors, label=colors, stacked=True)
axes[0,1].legend()
axes[1,0].scatter(x,y1)
axes[1,1].boxplot(y, labels=colors)
```

```python
# pie chart
plt.pie(a, autopct='%1.1f%%', explode=[0,0,0,0,0.1],
        startangle=90, shadow=True)
plt.show()
```

```python
### heatmap 활용
ta.groupby(['발생지시도','요일'])['사망자수'].sum().unstack()[['월','화','수','목','금','토','일']]
```

### 지도 - scatter
```python
import pandas as pd

import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'Malgun Gothic'

# scatter 
ta.plot.scatter('경도', '위도')
plt.show()

(ta['위도'] < 30).sum()

ta.loc[ta['위도'] < 30].values

ta = ta.loc[ta['위도'] >= 30]

ta.plot.scatter('경도', '위도')

# outlier 제거 
ta = ta.loc[ta['위도'] > 30]

ta.plot.scatter('경도', '위도')
```

### 지도 - folium
```python
# 한국 시도 경계 json 파일 읽기
# https://github.com/southkorea/southkorea-maps/blob/master/kostat/2013/json/skorea_provinces_geo_simple.json
geo_json = json.load(open('../data/skorea_provinces_geo_simple.json', encoding='utf-8'))

# ta_merged 파일 읽어오기
ta_merged 

# 대형사고율을 지도에 연결
folium.Choropleth(
    geo_data=geo_json,
    data=ta_merged,
    columns=['행정기관','대형사고율'], 
    key_on='feature.properties.name', 
    fill_color='Blues', # 'YlGn' 'Reds'
).add_to(m)
m
```
```python
    folium.CircleMarker([row['위도'], row['경도']], 
                        radius=3, color='red', 
                        fill_color='red').add_to(m)
```
```python
m.add_child(plugins.HeatMap(ta[['위도','경도']].values, radius=10)) 
```

### classification

```python
# Naive Bayes
from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()

# K-Nearest Neighbours
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier()

# Decision Tree
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()

# Random Forest
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(max_depth=2, random_state=0)

# Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier(max_depth=2, random_state=0)

# Neural Network
from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=0)
```

```python
from sklearn.model_selection import GridSearchCV

param_grid = [
    {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]},
  ]

clf = LogisticRegression(solver='liblinear', multi_class='auto')
grid_search = GridSearchCV(clf, param_grid, cv=5, # n_jobs=-1,
                           scoring='accuracy', verbose=2, return_train_score=True)
grid_search.fit(X_train, y_train)

y_pred = grid_search.predict(X_test)

print(grid_search)
print(metrics.classification_report(y_test, y_pred))
print(metrics.confusion_matrix(y_test, y_pred))
print(metrics.accuracy_score(y_pred,y_test))
```
